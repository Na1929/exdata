---
title: 'Analyses'
author: "KN"
date: '`r Sys.Date()`'
output: html_document
---

About
=====
- SPR conducted at Konan University, Jan, 2017
- 77 participants
- Target items: 
    + e "OnomatoAspect" 24
    + gano "Temp Loc/Manner gano" 24
- Pure fillers: 48
96 in total

Conditions:  
e (OnomatoAspect)  
a. for x once  
b. for x twice  
c. after x once  
d. after x twice  

e 1 a  
1分間|生徒が|ちらっと|黒板を|見たので|先生が|カンニングを|疑った。  
? 生徒は黒板を1分間見た Y  
e 1 b  
1分間|生徒が|ちらちら|黒板を|見たので|先生が|カンニングを|疑った。  
? 生徒は黒板を1分間見た Y  
e 1 c  
1分後|生徒が|ちらっと|黒板を|見たので|先生が|カンニングを|疑った。  
? 生徒は黒板を1分間見た N  
e 1 d  
1分後|生徒が|ちらちら|黒板を|見たので|先生が|カンニングを|疑った。  
? 生徒は黒板を1分間見た N  

gano (16 items)   
a. no x manner   
b. no x locative   
c. ga x manner   
d. ga x locative  

gano 1 a  
部長の|先月|こっそり|飲んだ|お酒は|取引先からの|差し入れだった。  
? 部長が飲んだお酒は取引先からの差し入れである Y  
gano 1 b  
部長の|先月|会議室で|飲んだ|お酒は|取引先からの|差し入れだった。  
? 部長が飲んだお酒は取引先からの差し入れである Y  
gano 1 c  
部長が|先月|こっそり|飲んだ|お酒は|取引先からの|差し入れだった。  
? 部長が飲んだお酒は取引先からの差し入れである Y  
gano 1 d  
部長が|先月|会議室で|飲んだ|お酒は|取引先からの|差し入れだった。  
? 部長が飲んだお酒は取引先からの差し入れである Y   


Retrieve RT data into alldata
=============================

First concatenate all the `.data` files into `alldata.txt`.  You can do it in a shell with:

  cat *.dat > alldata.txt

##### Load libraries

```{r}
#library(lme4)
library(lmerTest)
library(plyr)
library(dplyr)
library(ggplot2)
library(reshape)
library(gdata)      
library(MASS)
```


##### Declare the expt name that is relevant.
```{r}
ex<-"e"

# critical region
criticalregion<-3

# how far from the critical region do you want the plot to cover?
crplus<-4

# plot labels
ab<-"Durative"
cd<-"Non-durative"
ac<-"Simplex"
bd<-"Reduplicated"

# plot legend（凡例）のならび順はデフォルトではアルファベット順
# 逆順にしたい場合はここを1にする
revorderA <- 1  # ab vs cd
revorderB <- 1  # ac vs bd

# Factor labels in the plots
Alabel<-"Temporal Adv"
Blabel<-"Onomatopoeia"


# Trim incorrectly answered trials?  if( trimincorrect == 1 ){ rt_data<-subset(rt_data,correct==100) }
# No trimming: trimincorrect <- 0
trimincorrect <- 1





```


##### Load data:

```{r}
alldata<-read.table("alldata.txt",
                 header=FALSE)

colnames(alldata)<-c("subj","expt","item","cond","pos","word","cq","rt")
```



##### Create "spillover" column
#### Be sure that the package dplyr is loaded!!!  Otherwise, the lag function won't work properly

It's important to create spillover at this point because the order really matters.  

```{r}
# add one element to rt
spilloverraw <- c(0,alldata$rt)
# drop the last element 
spilloverraw <- spilloverraw[1:length(spilloverraw)-1]
# add to alldata
alldata$spilloverraw <- spilloverraw

# pos 0 and ? doesn't have a spillover
alldata$spilloverraw<-ifelse(alldata$pos=="0"|alldata$pos=="?",NA,alldata$spilloverraw)
head(alldata)

# centering & standardizing
alldata$spillover<-scale(alldata$spilloverraw, center=T, scale=T)

```


##### Exclude practice items

```{r}
alldata<-subset(alldata,expt!="practice")
```

##### cq（1/0）を100/0に変換

```{r}
alldata$cq<-ifelse(alldata$cq=="1",100,ifelse(alldata$cq=="0",0,NA))
```

##### correct columnをcqをもとに作成


```{r}
# Extract the question rows > select the relevant columns only
cqdata<-subset(alldata,pos=="?") %>%
  dplyr::select(subj,expt,item,cond,cq) 

# Rename "cq" as "correct"
names(cqdata)[names(cqdata)=="cq"]<-"correct"


#cqdata<-dplyr::select(cqdata,-cq) 

# Merge cqdata with alldata.  
alldata <- merge(alldata,cqdata,all=T)

# We don't need cq any longer.  Delete it.
alldata<-dplyr::select(alldata,-cq) 


```



Subject analyses
================

##### 変数初期化
```{r}
subjdataframe = c(); 
```

RT mean per subject
-------------------

##### SubjのRT meanを計算して蓄積
```{r}
tempdata<-alldata[alldata$pos!="?",]
#tapply(tempdata$rt,tempdata$subj,mean)
subjdataframe<-ddply(tempdata,.(subj),summarize,SubjRTmean=mean(rt,na.rm=T))
```


##### Each Subj RT meanのZ-scoreをdataframeに加える

scaleコマンドはデータをstandardize（Z-score変換）してくれる。なおscale(...,scale=F)とするとセンタリングのみ行ってくれる（つまりsdで割らない）。

```{r}
subjdataframe<-data.frame(subjdataframe, SubjRTZS=scale(subjdataframe$SubjRTmean));
```

##### asterisk columnを加える (outlier indication)
```{r}
subjdataframe<-data.frame(subjdataframe, RTmark=ifelse(subjdataframe$SubjRTZS>2.5, "*", " "));
```




Comprehension Accuracy per expt
----------------------------------
##### 変数初期化
```{r}
CAdataframe <- c(); 
myCA <- c()
myCAdataframe <- c()
```

##### Each exptのComprehension Accuracy情報

```{r}
CAdataframe<-ddply(alldata,.(expt),summarize,ExptMeanCA=mean(correct,na.rm=T))
```



##### Check data
```{r}
CAdataframe
```



Comprehension Accuracy per subject
----------------------------------

##### 変数初期化
```{r}
CAdataframe <- c(); 
myCA <- c()
myCAdataframe <- c()
summary(alldata)
```

##### Each subjのComprehension Accuracy情報を付加

```{r}
CAdataframe<-ddply(subset(alldata,pos=="?"),.(subj),summarize,SubjCA=mean(correct))
```

##### Merge RT data + CA data
```{r}
subjdataframe<-merge(subjdataframe,CAdataframe,all=T)
```

##### asteriskを加える (outlier indication)
```{r}
subjdataframe<-data.frame(subjdataframe, CAmark=ifelse(subjdataframe$SubjCA<200/3, "**", ifelse(subjdataframe$SubjCA<70, "*" , " ")));
```

##### Round the values (for the sake of readability)
(Not used in the actual analyses)
```{r}
subjrounded <- subjdataframe[c("subj","SubjRTmean","SubjRTZS","RTmark","SubjCA","CAmark")]

subjrounded$SubjRTmean <- round(subjrounded$SubjRTmean,0)
subjrounded$SubjRTZS <- round(subjrounded$SubjRTZS,1)
sdata <- subjrounded

write.csv(sdata,file="subjdata.csv",quote=F)
```

##### Merge RT/CA data with `alldata`
```{r}
alldata <- merge(alldata,subjdataframe,all=T);
write.csv(alldata,file="alldata.csv",quote=F)
```


##### Check subject data
Note: ak's comprehension questions are not really questions so this grand mean does not make much sense.  
```{r}
sdata
```


##### Mean, median
```{r}
mean(subjdataframe$SubjCA)
median(subjdataframe$SubjCA)
```


##### Is there someone with accuracy below 70?
```{r}
bs <- sdata[which(sdata$SubjCA <70),]
bs[order(bs$SubjCA),]
```

##### Is there someone with slow mean RT?
```{r}
bs <- sdata[which(sdata$SubjRTZS >3),]
bs[order(bs$SubjRTmean),]
```







Comprehension Accuracy per subject x exp
----------------------------------

##### 変数初期化
```{r}
CAdataframe <- c(); 
myCA <- c()
myCAdataframe <- c()
```

##### Each subjのComprehension Accuracy情報を付加
```{r}
CAdataframe<-ddply(subset(alldata,pos=="?"),.(expt,subj),summarize,SubjExptCA=mean(correct))
```

##### Exptごとのmeanとmedianを求める
```{r}
ddply(subset(alldata,pos=="?"),.(expt),summarize,ExptCAmean=mean(correct))
```


##### Merge data with `alldata`
```{r}
alldata <- merge(alldata,CAdataframe,all=T);

# sort when messed up
alldata <- alldata[order(alldata$subj,alldata$expt,alldata$item,alldata$cond,alldata$pos),]
rownames(alldata) <- c(1:nrow(alldata))

write.csv(alldata,file="alldata.csv",quote=F)
```


##### Check subject data
expt x subj
```{r}
subjexptdata <- CAdataframe[order(CAdataframe$expt,CAdataframe$SubjExptCA),]
# rowname may be messed up; fix it
rownames(subjexptdata) <- c(1:nrow(subjexptdata))
subjexptdata
write.csv(subjexptdata,file="subjexptdata.csv",quote=F)
```


##### Is there someone with accuracy below 70?
```{r}
bs <- subjexptdata[which(subjexptdata$SubjExptCA <70),]
bs[order(bs$expt,bs$SubjExptCA),]
```







Subj exclusion
==============
##### Who's slow

```{r}
sdata[which(sdata$SubjRTZS >3),]
```

##### Comprehension accuracy under 2/3

```{r}
bs <- subjexptdata[which(subjexptdata$SubjExptCA <70),]
bs[order(bs$expt,bs$SubjExptCA),]
```

```{r}
sdata[which(sdata$SubjCA < 200/3),]
subjexptdata[which(subjexptdata$SubjExptCA < 200/3 & subjexptdata$expt==ex),]
```



##### before trimming
Subject number before trimming
```{r}
unique(alldata$subj)
length(unique(alldata$subj))
```


##### trim by CA

```{r}
data<-alldata
data<-subset(data,SubjCA>=200/3)
unique(data$subj)
length(unique(data$subj))
data<-subset(data,SubjExptCA>=0)
unique(data$subj)
length(unique(data$subj))
```


##### trim by RTZS

```{r}
data<-subset(data,SubjRTZS<=99)
unique(data$subj)
length(unique(data$subj))
```

##### centering CA

```{r}
CAdataframe<-ddply(subset(data,pos=="?"),.(subj),summarize,SubjCA=mean(correct))
CAdataframe<-data.frame(CAdataframe,cCA=scale(CAdataframe$SubjCA,scale=F))
```


##### Merge RT data + CA data
```{r}
data<-merge(data,CAdataframe,all=T)
```


##### centering ExptCA

```{r}
SubjExptCA<-c()
CAdataframe<-ddply(subset(data,pos=="?"),.(subj,expt),summarize,SubjExptCA=mean(correct))
for(i in unique(CAdataframe$expt)){   
  # それぞれのexptのsubj CAmeanを抜き出し
  mySubjExptCA <- CAdataframe[CAdataframe$expt==i,];
  # centering
  mySubjExptCA<-data.frame(mySubjExptCA,cExptCA=scale(mySubjExptCA$SubjExptCA,scale=F))
  # それを蓄積
  SubjExptCA<-rbind(SubjExptCA,mySubjExptCA)
}

data <- merge(data,SubjExptCA,all=T);

# sort when messed up
#data <- data[order(data$subj,data$expt,data$item,data$cond,data$pos),]
#rownames(data) <- c(1:nrow(data))

```


Isolate the data from the relevant experiment
=============================================
```{r}
data<-subset(data,expt==ex)
unique(data$expt)
```

Reading time summary
====================

##### Omit questions
```{r}
rt_data<-subset(data,pos!="?")
```

##### Create "region" column from "pos"
`pos` starts from zero and thus is confusing, so create `region` which starts from 1.  This is done at this point because `pos` originally contained ? as well as position number.  ? is now eliminated.  Note: `as.character` gets factors back to characters.  I don't know why but factors cannot get directly back to numeric.

```{r}
rt_data$region<-as.numeric(as.character(rt_data$pos))+1
```

##### Make sure factors are treated as factors
```{r}
rt_data$subj<-factor(rt_data$subj)
rt_data$expt<-factor(rt_data$expt)
rt_data$item<-factor(rt_data$item)
rt_data$cond<-factor(rt_data$cond)
rt_data$word<-factor(rt_data$word)
```

##### Correctly answered trials only? (trimincorrect)

Note: if you do this trimming at this point, it precedes the z-score computation.

```{r}
before <- length(rt_data$rt)
before
```


```{r}
if( trimincorrect == 1 ){
  rt_data<-subset(rt_data,correct==100)
}
```

```{r}
after <- length(rt_data$rt)
after
```

```{r}
(before-after)*100/before
```

##### RT trimming?  
100msを切るRTが見受けられるのでさすがにカットしたほうが良いかと。
```{r}
subset(rt_data,rt<200 & region==1,c("expt","cond","region","rt"))
subset(rt_data,rt<200 & region==2,c("expt","cond","region","rt"))
subset(rt_data,rt<200 & region==3,c("expt","cond","region","rt"))
subset(rt_data,rt<200 & region==4,c("expt","cond","region","rt"))
subset(rt_data,rt<200 & region==5,c("expt","cond","region","rt"))

subset(rt_data,rt>3000 & region==1,c("expt","cond","region","rt"))
subset(rt_data,rt>3000 & region==2,c("expt","cond","region","rt"))
subset(rt_data,rt>3000 & region==3,c("expt","cond","region","rt"))
subset(rt_data,rt>3000 & region==4,c("expt","cond","region","rt"))
subset(rt_data,rt>3000 & region==5,c("expt","cond","region","rt"))

tapply(rt_data$rt, rt_data$region, mean)
tapply(rt_data$rt, paste(rt_data$region, rt_data$cond), mean)
```

rt trimming

```{r}
rt_data_notrim <- rt_data

rt_data<-subset(rt_data_notrim,rt>=150 & rt<=10000)

```

Generate z-scores for variable A using the scale() function
scale(A, center = TRUE, scale = TRUE)

Be aware that this z-score computation per region x cond cell is { before / after } the yes/no trimming.

```{r}
myRT <- c()
newdataframe <- c()
for(i in unique(rt_data$region)){   
  for(j in unique(rt_data$cond)){
    # abstract rt column in the region x cond cell
    myRT <- subset(rt_data, region==i & cond==j);
    # compute z-score
    myRT$RxCzs <- scale(myRT$rt, center = T, scale = T);
    # 蓄積
    newdataframe<-rbind(newdataframe,myRT);
    }
}; 

rt_data <- merge(rt_data,newdataframe,all=T)

```

##### check outliers
```{r}
bs <- rt_data[which(rt_data$RxCzs >3),]
bs <- bs[c("subj","item","region","cond","rt","RxCzs")]
bs[order(bs$region,bs$cond,bs$RxCzs),]
```

```{r}
bs <- rt_data[which(rt_data$RxCzs >5),]
bs <- bs[c("subj","item","region","cond","rt","RxCzs")]
bs[order(bs$region,bs$cond,bs$RxCzs),]
```


##### rt trimming based on RxCzs
```{r}
tapply(rt_data$rt, paste(rt_data$region, rt_data$cond), mean)

rt_data<-subset(rt_data,RxCzs<3)

tapply(rt_data$rt, paste(rt_data$region, rt_data$cond), mean)

```


```{r}
(length(rt_data_notrim$rt)-length(rt_data$rt))*100/length(rt_data_notrim$rt)
```




## Summary (interim)

のちにtrimmingをする（かもしれない）ので，このファイルの最後でもういちどサマリーとプロットの最終盤を生成します。

##### Extract data for summary

###### Critical region plus 3
```{r}
rtg <- subset(rt_data,region<=criticalregion+crplus)

```


##### summary
```{r}
# Raw rt version
rt_data_summary <- ddply(rtg, .(cond,region), summarise, N=length(rt), mean=mean(rt), sd=sd(rt), se=sd/sqrt(N),ci=qt(0.975,df=N-1)*se)
```

##### Coding conditions for plot labels
```{r}
rt_data_summary$A<-ifelse(rt_data_summary$cond%in%c("a","b"),ab,cd)
rt_data_summary$B<-ifelse(rt_data_summary$cond%in%c("a","c"),ac,bd)
rt_data_summary$Conditions<-paste(rt_data_summary$A,rt_data_summary$B,sep=":")
rt_data_summary$B

# Change the order of the legend labels
if( revorderA == 1 ){  
  rt_data_summary$A<-factor(rt_data_summary$A, levels=rev(levels(factor(rt_data_summary$A))))}
if( revorderB == 1 ){  
  rt_data_summary$B<-factor(rt_data_summary$B, levels=rev(levels(factor(rt_data_summary$B))))
}

  
rt_data_summary
#rrt_data_summary
```


## Plots

See the following references for ggplot codes:

http://www.cookbook-r.com/Graphs/Shapes_and_line_types/

http://meme.biology.tohoku.ac.jp/students/iwasaki/rstats/ggplot2.html



##### Raw RT
Base
```{r}
g <- ggplot(rt_data_summary,aes(x=region,y=mean,group=Conditions))
```

Add lines
```{r}
g <- g + geom_line(size=1,aes(linetype=A))
g <- g + scale_linetype_manual(values=c("dotdash","solid"))
g <- g + labs(linetype=Alabel)
```

Add points
```{r}
g <- g + geom_point(size=5,aes(shape=B,fill=B))
g <- g + scale_shape_manual(values=c(21,24,24,25))
g <- g + scale_fill_manual(values=c("white","black","white","black"))
g <- g + labs(shape=Blabel)
g <- g + labs(fill=Blabel)
```

Add error bars
```{r}
g <- g + geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width=.3)
```

Adjust x-axis breaks and labels
```{r}
g <- g + scale_x_continuous(breaks=seq(1, 8, by=1),labels=c("Temp Adv", "Subj",
                              "Onom", "Mod", "Verb", "6","7","8"))

```

Create Theme

```{r}
g <- g + theme(      
                 # 背景を消す
                 panel.background = element_rect(fill = "white"),
                 panel.border = element_blank(), axis.line = element_line(),
                 # 凡例の設定
                 legend.position    = c(1, 1),
                 legend.justification = c(1,1),
                 #legend.title = element_blank(), 
                 legend.title = element_text(family = "Times", size = 15),
                 legend.text = element_text(size = 15, family="Times"),
                 legend.key = element_blank(), 
                 # テキスト形式の設定
                 axis.title.x = element_text(family = "Times", size = 20), 
                 axis.title.y = element_text(family = "Times",size = 20), 
                 axis.text.x = element_text(angle =   45, size = 15, hjust = 1,family = "Times"), 
                 axis.text.y = element_text(size = 15, hjust = 0.5, family = "Times"),
              )

```


Adjust appearance
```{r}
#g <- g + theme_classic(base_size=20, base_family="HiraKakuProN-W3")
#g <- g + theme(base_size=20, base_family="Times", axis.text.x = element_text(angle = 45, hjust = 1))
g <- g + labs(x="Region", y="RT (ms)")
print(g)
```


###### a vs c
```{r}
gsummary <- subset(rt_data_summary,B==ac)
g <- ggplot(gsummary,aes(x=region,y=mean,group=Conditions))
```

Add lines
```{r}
g <- g + geom_line(size=1,aes(linetype=B))
g <- g + scale_linetype_manual(values=c("dashed"))
g <- g + labs(linetype=Blabel)
```

Add points
```{r}
g <- g + geom_point(size=5,aes(shape=A,fill=A))
# 21 (circle), 22 (square), 23 (lozenge), 24 (triangle), 25 (rev triangle)
g <- g + scale_shape_manual(values=c(24,21))
g <- g + scale_fill_manual(values=c("black","white"))
g <- g + labs(shape=Alabel)
g <- g + labs(fill=Alabel)

```

Add error bars
```{r}
g <- g + geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width=.3)
```

Adjust x-axis breaks
```{r}
g <- g + scale_x_continuous(breaks=seq(1, 10, by=1))
```

Adjust appearance
```{r}
#g <- g + theme_classic(base_size=20, base_family="HiraKakuProN-W3")
g <- g + theme_classic(base_size=20, base_family="Times")
g <- g + labs(x="Region", y="Transformed RT", title="Mean RTs")
print(g)
```


###### b vs d
```{r}
gsummary <- subset(rt_data_summary,B==bd)
g <- ggplot(gsummary,aes(x=region,y=mean,group=Conditions))
```

Add lines
```{r}
g <- g + geom_line(size=1,aes(linetype=B))
g <- g + scale_linetype_manual(values=c("solid"))
g <- g + labs(linetype=Blabel)
```

Add points
```{r}
g <- g + geom_point(size=5,aes(shape=A,fill=A))
# 21 (circle), 22 (square), 23 (lozenge), 24 (triangle), 25 (rev triangle)
g <- g + scale_shape_manual(values=c(24,21))
g <- g + scale_fill_manual(values=c("black","white"))
g <- g + labs(shape=Alabel)
g <- g + labs(fill=Alabel)
```

Add error bars
```{r}
g <- g + geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width=.3)
```

Adjust x-axis breaks
```{r}
g <- g + scale_x_continuous(breaks=seq(1, 10, by=1))
```

Adjust appearance
```{r}
#g <- g + theme_classic(base_size=20, base_family="HiraKakuProN-W3")
g <- g + theme_classic(base_size=20, base_family="Times")
g <- g + labs(x="Region", y="Transformed RT", title="Mean RTs")
print(g)
```



###### a vs b
```{r}
gsummary <- subset(rt_data_summary,A==ab)
g <- ggplot(gsummary,aes(x=region,y=mean,group=Conditions))
```

Add lines
```{r}
g <- g + geom_line(size=1,aes(linetype=A))
g <- g + scale_linetype_manual(values=c("solid"))
g <- g + labs(linetype=Alabel)
```

Add points
```{r}
g <- g + geom_point(size=5,aes(shape=B,fill=B))
# 21 (circle), 22 (square), 23 (lozenge), 24 (triangle), 25 (rev triangle)
g <- g + scale_shape_manual(values=c(24,21))
g <- g + scale_fill_manual(values=c("black","white"))
g <- g + labs(shape=Blabel)
g <- g + labs(fill=Blabel)
```

Add error bars
```{r}
g <- g + geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width=.3)
```

Adjust x-axis breaks
```{r}
g <- g + scale_x_continuous(breaks=seq(1, 10, by=1))
```

Adjust appearance
```{r}
#g <- g + theme_classic(base_size=20, base_family="HiraKakuProN-W3")
g <- g + theme_classic(base_size=20, base_family="Times")
g <- g + labs(x="Region", y="Transformed RT", title="Mean RTs")
print(g)
```


###### c vs d
```{r}
gsummary <- subset(rt_data_summary,A==cd)
g <- ggplot(gsummary,aes(x=region,y=mean,group=Conditions))
```

Add lines
```{r}
g <- g + geom_line(size=1,aes(linetype=A))
g <- g + scale_linetype_manual(values=c("dashed"))
g <- g + labs(linetype=Alabel)
```

Add points
```{r}
g <- g + geom_point(size=5,aes(shape=B,fill=B))
# 21 (circle), 22 (square), 23 (lozenge), 24 (triangle), 25 (rev triangle)
g <- g + scale_shape_manual(values=c(24,21))
g <- g + scale_fill_manual(values=c("black","white"))
g <- g + labs(shape=Blabel)
g <- g + labs(fill=Blabel)
```

Add error bars
```{r}
g <- g + geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width=.3)
```

Adjust x-axis breaks
```{r}
g <- g + scale_x_continuous(breaks=seq(1, 10, by=1))
```

Adjust appearance
```{r}
#g <- g + theme_classic(base_size=20, base_family="HiraKakuProN-W3")
g <- g + theme_classic(base_size=20, base_family="Times")
g <- g + labs(x="Region", y="Transformed RT", title="Mean RTs")
print(g)
```

##### Interaction
Base
```{r}
rtg <- subset(rt_data_summary,region==3)
g <- ggplot(rtg,aes(x=A,y=mean,group=Conditions))
```

Add lines
```{r}
g <- g + geom_line(size=1,aes(group=B,linetype=B))
g <- g + scale_linetype_manual(values=c("dotdash","solid"))
g <- g + labs(linetype=Blabel)
```

Add points
```{r}
g <- g + geom_point(size=8,aes(shape=B,fill=B))
g <- g + scale_shape_manual(values=c(21,24,24,25))
g <- g + scale_fill_manual(values=c("white","black","white","black"))
g <- g + labs(shape=Blabel)
g <- g + labs(fill=Blabel)
```

Add error bars
```{r}
g <- g + geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.1)
```

Adjust x-axis breaks
```{r}
#g <- g + scale_x_continuous(breaks=seq(1, 10, by=1))
```

Adjust appearance
```{r}
#g <- g + theme_classic(base_size=20, base_family="HiraKakuProN-W3")
g <- g + theme_classic(base_size=20, base_family="Times")
g <- g + labs(x="Temporal Adv", y="RT (ms)", title="Onomatopoeia Region")
print(g)
```

##### Interaction
Base
```{r}
rtg <- subset(rt_data_summary,region==4)
g <- ggplot(rtg,aes(x=A,y=mean,group=Conditions))
```

Add lines
```{r}
g <- g + geom_line(size=1,aes(group=B,linetype=B))
g <- g + scale_linetype_manual(values=c("dotdash","solid"))
g <- g + labs(linetype=Blabel)
```

Add points
```{r}
g <- g + geom_point(size=8,aes(shape=B,fill=B))
g <- g + scale_shape_manual(values=c(21,24,24,25))
g <- g + scale_fill_manual(values=c("white","black","white","black"))
g <- g + labs(shape=Blabel)
g <- g + labs(fill=Blabel)
```

Add error bars
```{r}
g <- g + geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.1)
```

Adjust x-axis breaks
```{r}
#g <- g + scale_x_continuous(breaks=seq(1, 10, by=1))
```

Adjust appearance
```{r}
#g <- g + theme_classic(base_size=20, base_family="HiraKakuProN-W3")
g <- g + theme_classic(base_size=20, base_family="Times")
g <- g + labs(x="Temporal Adv", y="RT (ms)", title="Onom spillover")
print(g)
```


##### Interaction
Base
```{r}
rtg <- subset(rt_data_summary,region==5)
g <- ggplot(rtg,aes(x=A,y=mean,group=Conditions))
```

Add lines
```{r}
g <- g + geom_line(size=1,aes(group=B,linetype=B))
g <- g + scale_linetype_manual(values=c("dotdash","solid"))
g <- g + labs(linetype=Blabel)
```

Add points
```{r}
g <- g + geom_point(size=8,aes(shape=B,fill=B))
g <- g + scale_shape_manual(values=c(21,24,24,25))
g <- g + scale_fill_manual(values=c("white","black","white","black"))
g <- g + labs(shape=Blabel)
g <- g + labs(fill=Blabel)
```

Add error bars
```{r}
g <- g + geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.1)
```

Adjust x-axis breaks
```{r}
#g <- g + scale_x_continuous(breaks=seq(1, 10, by=1))
```

Adjust appearance
```{r}
#g <- g + theme_classic(base_size=20, base_family="HiraKakuProN-W3")
g <- g + theme_classic(base_size=20, base_family="Times")
g <- g + labs(x="Temporal Adv", y="RT (ms)", title="Verb Region (V)")
print(g)
```

##### Interaction
Base
```{r}
rtg <- subset(rt_data_summary,region==6)
g <- ggplot(rtg,aes(x=A,y=mean,group=Conditions))
```

Add lines
```{r}
g <- g + geom_line(size=1,aes(group=B,linetype=B))
g <- g + scale_linetype_manual(values=c("dotdash","solid"))
g <- g + labs(linetype=Blabel)
```

Add points
```{r}
g <- g + geom_point(size=8,aes(shape=B,fill=B))
g <- g + scale_shape_manual(values=c(21,24,24,25))
g <- g + scale_fill_manual(values=c("white","black","white","black"))
g <- g + labs(shape=Blabel)
g <- g + labs(fill=Blabel)
```

Add error bars
```{r}
g <- g + geom_errorbar(aes(ymin=mean-ci, ymax=mean+ci), width=.1)
```

Adjust x-axis breaks
```{r}
#g <- g + scale_x_continuous(breaks=seq(1, 10, by=1))
```

Adjust appearance
```{r}
#g <- g + theme_classic(base_size=20, base_family="HiraKakuProN-W3")
g <- g + theme_classic(base_size=20, base_family="Times")
g <- g + labs(x="Temporal Adv", y="RT (ms)", title="Spillover region")
print(g)
```













Analyses
========


### Analysis 



Coding factors (with centering)
-------------------------------

##### CONDITIONS:

```{r}

rt_data$adv<-ifelse(rt_data$cond%in%c("a","b"),1,-1)
rt_data$onom<-ifelse(rt_data$cond%in%c("a","c"),1,-1)
rt_data$int<-rt_data$adv*rt_data$onom

# For pairwise comparisons
rt_data$simplexVSredup_dur <-ifelse(rt_data$adv==1,
                          ifelse(rt_data$onom==1,1,-1),
                          0)
rt_data$simplexVSredup_nondur <-ifelse(rt_data$adv==-1,
                          ifelse(rt_data$onom==1,1,-1),
                          0)
rt_data$durVSnondur_simplex <-ifelse(rt_data$onom==1,
                          ifelse(rt_data$adv==1,1,-1),
                          0)
rt_data$durVSnondur_redup <-ifelse(rt_data$onom==-1,
                          ifelse(rt_data$adv==1,1,-1),
                          0)

```

rt_data check
```{r}
dc <- subset(rt_data,cond=="a",c(cond,word,adv,onom,int))
head(dc, n=7)
dc <- subset(rt_data,cond=="b",c(cond,word,adv,onom,int))
head(dc, n=7)
dc <- subset(rt_data,cond=="c",c(cond,word,adv,onom,int))
head(dc, n=7)
dc <- subset(rt_data,cond=="d",c(cond,word,adv,onom,int))
head(dc, n=7)

```




##### Make sure factors are treated as factors
```{r}
rt_data$subj<-factor(rt_data$subj)
rt_data$expt<-factor(rt_data$expt)
rt_data$item<-factor(rt_data$item)
rt_data$cond<-factor(rt_data$cond)
rt_data$word<-factor(rt_data$word)
```

#### Critical region
```{r}
cregion<-subset(rt_data,region==criticalregion)
```

##### Check words
```{r}
sort(unique(cregion$word))
```


##### Max model
```{r}
mm<-lmer(rt~adv*onom+
           (1+adv*onom|subj)+(1+adv*onom|item),
           control=lmerControl(optimizer="bobyqa"),
           cregion)
summary(mm)
(step_res <- step(mm, reduce.fixed = F))
final <- get_model(step_res)
summary(final)
anova(final)
```



#### Critical region +
```{r}
cr <- criticalregion +1
cregion<-subset(rt_data,region==cr)
```

##### Check words
```{r}
sort(unique(cregion$word))
```


##### Max model
```{r}
mm<-lmer(rt~adv*onom+
           (1+adv*onom|subj)+(1+adv*onom|item),
           control=lmerControl(optimizer="bobyqa"),
           cregion)

summary(mm)

(step_res <- step(mm, reduce.fixed = F))
final <- get_model(step_res)
summary(final)
anova(final)
```




#### Critical region ++
```{r}
cr <- criticalregion +2
cregion<-subset(rt_data,region==cr)
```

##### Check words
```{r}
sort(unique(cregion$word))
```


##### Max model
```{r}
mm<-lmer(rt~adv*onom+
           (adv*onom+1|subj)+(adv*onom+1|item),
           control=lmerControl(optimizer="bobyqa"),
           cregion)
summary(mm)
(step_res <- step(mm, reduce.fixed = F))
final <- get_model(step_res)
summary(final)
anova(final)
```


#### Critical region +++
```{r}
cr <- criticalregion +3
cregion<-subset(rt_data,region==cr)
```

##### Check words
```{r}
sort(unique(cregion$word))
```


##### Max model
```{r}
mm<-lmer(rt~adv*onom+
           (1+adv*onom|subj)+(1+adv*onom|item),
           control=lmerControl(optimizer="bobyqa"),
           cregion)
summary(mm)
(step_res <- step(mm, reduce.fixed = F))
final <- get_model(step_res)
summary(final)
anova(final)
```




##### Post hoc multiple pairwise comparisons to test the interaction
```{r}
mmm<-lmer(rt~simplexVSredup_dur+simplexVSredup_nondur+adv+
           (adv*onom+1|subj)+(adv*onom+1|item),
           control=lmerControl(optimizer="bobyqa"),
           cregion)
summary(mmm)
(step_res <- step(mmm, reduce.fixed = F))
final <- get_model(step_res)
summary(final)
anova(final)
```

```{r}
mmm<-lmer(rt~durVSnondur_simplex+durVSnondur_redup+onom+
           (adv*onom+1|subj)+(adv*onom+1|item),
           control=lmerControl(optimizer="bobyqa"),
           cregion)
summary(mmm)
(step_res <- step(mmm, reduce.fixed = F))
final <- get_model(step_res)
summary(final)
anova(final)

```

